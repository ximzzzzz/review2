### 1. 몬테카를로(montecarlo)

​	샘플링 방법, 복잡하거나 분포를 알 수 없는 경우에 근사하는 방식. 



### 2. 마르코프 체인(Markov chain)

​	t시점에서 무언가를 예측할 때 영향을 주는건 바로 '그 전 사건(t-1)' 이라고 가정하고 계산하는 방식

​	t-2, t-3... 은 무시한다.

  

### 3. 몬테카를로 마르코프 체인(MCMC)

​	마르코프 체인가정을 기반으로하는 몬테카를로 샘플링.

​	기존 몬테카를로 샘플링은 각 사건은 독립이라는 가정으로 랜덤하게 추출했지만, 

​	MCMC는 몬테카를로 체인 방식으로 이전 샘플을 고려하여 현재 샘플링함



#### 4. 깁스 샘플링(Gibbs sampling)

​	MCMC의 한 종류.

​	이전 샘플을 고려해 현재 샘플링을 한다는점에선 동일하지만, 샘플링 시 나머지 변수는 그대로 두고

​	한변수에만 변화를 준다는 점이 다르다.

​	



참조 : https://ratsgo.github.io/statistics/2017/05/31/gibbs/