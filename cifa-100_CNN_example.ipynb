{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test):\n",
    "\n",
    "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# from augment import augment\n",
    "import os\n",
    "from keras.datasets.cifar100 import load_data\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "x_train, x_test = normalize(x_train, x_test)\n",
    "# y_train = to_categorical(y_train, 100)\n",
    "# y_test = to_categorical(y_test, 100)\n",
    "\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "num_epochs = 30\n",
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_display = 100\n",
    "\n",
    "def get_model(X, by, is_reuse):\n",
    "    inputs = X\n",
    "    with tf.variable_scope('first'):\n",
    "        conv1 = tf.layers.conv2d(X, 32, 3, padding='same',\n",
    "                                kernel_initializer=tf.initializers.truncated_normal(stddev=0.02),) # (None, 32, 32, 128)\n",
    "        bn1 = tf.layers.batch_normalization(conv1,\n",
    "                                            name='bn1',\n",
    "                                            reuse=tf.AUTO_REUSE)\n",
    "        h1 = tf.nn.relu(bn1)\n",
    "        maxpool1 = tf.layers.max_pooling2d(h1, 2, 2) # (None, 16, 16, 128)\n",
    "        dropout1 = tf.layers.dropout(maxpool1, rate = 0.5,training=training)\n",
    "        \n",
    "    with tf.variable_scope('second'):\n",
    "        conv2 = tf.layers.conv2d(dropout1, 64, 3, padding='same',\n",
    "                               kernel_initializer=tf.initializers.truncated_normal(stddev=0.02))\n",
    "        bn2 = tf.layers.batch_normalization(conv2,\n",
    "                                            name='bn2',\n",
    "                                            reuse=tf.AUTO_REUSE)\n",
    "        h2 = tf.nn.relu(bn2)\n",
    "        maxpool2 = tf.layers.max_pooling2d(h2, 2, 2) # (None, 7, 7, 256)\n",
    "#         outs += outs \n",
    "    with tf.variable_scope('third'):\n",
    "        conv3 = tf.layers.conv2d(maxpool2, 128, 3, padding='same',\n",
    "                               kernel_initializer=tf.initializers.truncated_normal(stddev=0.02))\n",
    "        bn3 = tf.layers.batch_normalization(conv3,\n",
    "                                            name='bn3',\n",
    "                                            reuse=tf.AUTO_REUSE)\n",
    "        h3 = tf.nn.relu(bn3)\n",
    "        maxpool3 = tf.layers.max_pooling2d(h3, 2, 2) # (None, 3, 3, 64)\n",
    "        dropout3 = tf.layers.dropout(maxpool3, 0.5, training=training)\n",
    "        \n",
    "    with tf.variable_scope('fourth'):\n",
    "#         outs += outs \n",
    "        conv4 = tf.layers.conv2d(dropout3, 256, 3, padding='same',\n",
    "                               kernel_initializer=tf.initializers.truncated_normal(stddev=0.02)) # (None, 28, 28, 128)\n",
    "\n",
    "        bn4 = tf.layers.batch_normalization(conv4)\n",
    "        h4 = tf.nn.relu(bn4)\n",
    "        maxpool4 = tf.layers.max_pooling2d(h4, 2, 2) # (None, 14, 14, 128)\n",
    "        dropout4 = tf.layers.dropout(maxpool4, 0.5 ,training=training)\n",
    "        \n",
    "    with tf.variable_scope('fifth'):\n",
    "        conv5 = tf.layers.conv2d(dropout4, 512, 3, padding='same',\n",
    "                               kernel_initializer=tf.initializers.truncated_normal(stddev=0.02))\n",
    "        bn5 = tf.layers.batch_normalization(conv5)\n",
    "        h5 = tf.nn.relu(bn5)\n",
    "        maxpool5 = tf.layers.max_pooling2d(h5, 2, 2) # (None, 7, 7, 256)\n",
    "        \n",
    "    flat = tf.reshape(maxpool5, (-1, maxpool5.shape[1]*maxpool5.shape[2]*maxpool5.shape[3]))\n",
    "    with tf.variable_scope('dense'):\n",
    "        dense1 = tf.layers.dense(flat, 386,\n",
    "                              kernel_initializer=tf.initializers.truncated_normal(stddev=0.02))\n",
    "        dense_h = tf.nn.relu(dense1)\n",
    "        dense_dropout = tf.layers.dropout(dense_h,0.5)\n",
    "        outputs = tf.layers.dense(dense_h, 100)\n",
    "    softmax = tf.nn.softmax(outputs)\n",
    "    one_hot = tf.squeeze(tf.one_hot(by, 100),axis=1)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, \n",
    "                                                      labels=one_hot))\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate,).minimize(loss)\n",
    "\n",
    "    preds = tf.argmax(softmax, axis=1)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.squeeze(by, axis=1), preds), tf.float32))\n",
    "    init = tf.global_variables_initializer()\n",
    "    return {\n",
    "        'loss': loss,\n",
    "        'opt': opt,\n",
    "        'preds': preds,\n",
    "        'acc': acc,\n",
    "        'init': init,\n",
    "        'softmax' : softmax\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 32, 32, 3],name = 'input_data')\n",
    "by = tf.placeholder(tf.int64, name ='y_input_data')\n",
    "training = tf.placeholder(tf.bool, name = 'training_bool')\n",
    "model = get_model(X, by, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 4.1856 acc 0.0533\n",
      "Current iteration 2\n",
      "loss 3.9122 acc 0.1133\n",
      "Current iteration 3\n",
      "loss 3.6389 acc 0.1333\n",
      "Current iteration 4\n",
      "loss 3.4629 acc 0.1933\n",
      "Current iteration 5\n",
      "loss 3.2745 acc 0.2200\n",
      "Current iteration 6\n",
      "loss 3.1841 acc 0.2200\n",
      "Current iteration 7\n",
      "loss 3.0797 acc 0.2533\n",
      "Current iteration 8\n",
      "loss 3.0206 acc 0.2933\n",
      "Current iteration 9\n",
      "loss 2.8793 acc 0.2533\n",
      "Current iteration 10\n",
      "loss 2.7345 acc 0.3333\n",
      "Current iteration 11\n",
      "loss 2.7995 acc 0.3467\n",
      "Current iteration 12\n",
      "loss 2.7544 acc 0.3200\n",
      "Current iteration 13\n",
      "loss 2.7639 acc 0.3333\n",
      "Current iteration 14\n",
      "loss 2.6846 acc 0.3333\n",
      "Current iteration 15\n",
      "loss 2.7106 acc 0.3533\n",
      "Current iteration 16\n",
      "loss 2.5576 acc 0.3333\n",
      "Current iteration 17\n",
      "loss 2.6235 acc 0.3467\n",
      "Current iteration 18\n",
      "loss 2.6128 acc 0.3667\n",
      "Current iteration 19\n",
      "loss 2.4458 acc 0.3600\n",
      "Current iteration 20\n",
      "loss 2.4118 acc 0.3400\n",
      "Current iteration 21\n",
      "loss 2.4754 acc 0.3733\n",
      "Current iteration 22\n",
      "loss 2.4182 acc 0.3667\n",
      "Current iteration 23\n",
      "loss 2.4925 acc 0.3733\n",
      "Current iteration 24\n",
      "loss 2.2459 acc 0.4333\n",
      "Current iteration 25\n",
      "loss 2.5547 acc 0.3733\n",
      "Current iteration 26\n",
      "loss 2.3852 acc 0.3867\n",
      "Current iteration 27\n",
      "loss 2.2433 acc 0.4333\n",
      "Current iteration 28\n",
      "loss 2.3062 acc 0.4333\n",
      "Current iteration 29\n",
      "loss 2.2822 acc 0.4333\n",
      "Current iteration 30\n",
      "loss 2.2717 acc 0.4400\n",
      "TEST: loss 2.2132 acc 0.4262\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(model['init'])\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "        \n",
    "        for ind_ in range(0, int(50000 / batch_size)):\n",
    "            batch_X = x_train[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            batch_by = y_train[ind_*batch_size:(ind_+1)*batch_size]\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [model['opt'], model['loss'], model['acc']],\n",
    "                feed_dict={X: batch_X, by: batch_by, training :True})\n",
    "#             print(sess.run(model['preds'], feed_dict={X:x_train[:10], training:False}))\n",
    "#             if ind_ % num_display == 0:\n",
    "        print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    for ind_ in range(0, 10):\n",
    "        cur_loss, cur_acc = sess.run(\n",
    "                    [model['loss'], model['acc']],\n",
    "                    feed_dict={X: x_test[ind_*1000:(ind_+1)*1000], \n",
    "                               by: y_test[ind_*1000:(ind_+1)*1000],\n",
    "                              training : False})\n",
    "        cur_loss_all += cur_loss\n",
    "        cur_acc_all += cur_acc\n",
    "    print('TEST: loss {0:.4f} acc {1:.4f}'.format(cur_loss_all / 10.0, \n",
    "                                              cur_acc_all / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-4691697bec16>:2: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([90, 38, 99, 22, 55, 79, 86, 37, 92, 81], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.arg_max(tf.squeeze(tf.one_hot(y_train[:10], 100), axis=1),1).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 85, 85, 85, 62], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(model['init'])\n",
    "sess.run(model['preds'], feed_dict={X:x_train[:5], training:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90, 38, 99, 22, 55])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(y_train[:5], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
